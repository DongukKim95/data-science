{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 웹 애플리케이션에 머신 러닝 모델 내장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ch8에서 학습한 로지스틱 회귀 모델 다시 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "# 텍스트 데이터 정제. 불용어 제외한 단어 토큰으로 분리\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower() +\n",
    "                  ' '.join(emoticons).replace('-', ''))\n",
    "    tokenized = [w for w in text.split() if w not in stop]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 번에 문서 하나씩 읽어서 반환하는 제너레이터(generator) 함수\n",
    "\n",
    "def stream_docs(path):\n",
    "    with open(path, 'r', encoding='utf-8') as csv:\n",
    "        next(csv)  # 헤더 넘기기\n",
    "        for line in csv:\n",
    "            text, label = line[:-3], int(line[-2])\n",
    "            yield text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\"In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, Greenwich, Connecticut. On the Mischief Night, eve of Halloween, she was murdered in the backyard of her house and her murder remained unsolved. Twenty-two years later, the writer Mark Fuhrman (Christopher Meloni), who is a former LA detective that has fallen in disgrace for perjury in O.J. Simpson trial and moved to Idaho, decides to investigate the case with his partner Stephen Weeks (Andrew Mitchell) with the purpose of writing a book. The locals squirm and do not welcome them, but with the support of the retired detective Steve Carroll (Robert Forster) that was in charge of the investigation in the 70\\'s, they discover the criminal and a net of power and money to cover the murder.<br /><br />\"\"Murder in Greenwich\"\" is a good TV movie, with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a Kennedy. The powerful and rich family used their influence to cover the murder for more than twenty years. However, a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed. The screenplay shows the investigation of Mark and the last days of Martha in parallel, but there is a lack of the emotion in the dramatization. My vote is seven.<br /><br />Title (Brazil): Not Available\"',\n",
       " 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stream_docs 함수 테스트\n",
    "\n",
    "next(stream_docs(path='movie_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream_docs 함수에서 문서를 읽어 size 매개변수에서 지정한 만큼 문서 반환하는 함수\n",
    "\n",
    "def get_minibatch(doc_stream, size):\n",
    "    docs, y = [], []\n",
    "    try:\n",
    "        for _ in range(size):\n",
    "            text, label = next(doc_stream)\n",
    "            docs.append(text)\n",
    "            y.append(label)\n",
    "    except StopIteration:\n",
    "        pass\n",
    "    return docs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 외부 메모리 학습에 CountVectorizer, TfidfVectorizer 사용 못함\n",
    "# HashingVectorizer 사용\n",
    "\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "vect = HashingVectorizer(decode_error='ignore',\n",
    "                         n_features=2**21,\n",
    "                         preprocessor=None,\n",
    "                         tokenizer=tokenizer)\n",
    "clf = SGDClassifier(loss='log', random_state=1, max_iter=1)\n",
    "doc_stream = stream_docs(path='movie_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:42\n"
     ]
    }
   ],
   "source": [
    "# 외부 메모리 학습 시작\n",
    "\n",
    "import pyprind\n",
    "\n",
    "pbar = pyprind.ProgBar(45)\n",
    "classes = np.array([0, 1])\n",
    "\n",
    "for _ in range(45):\n",
    "    X_train, y_train = get_minibatch(doc_stream, size=1000)\n",
    "    if not X_train:\n",
    "        break\n",
    "    X_train = vect.transform(X_train)\n",
    "    clf.partial_fit(X_train, y_train, classes=classes)\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.868\n"
     ]
    }
   ],
   "source": [
    "# 모델 성능 평가\n",
    "\n",
    "X_test, y_test = get_minibatch(doc_stream, size=5000)\n",
    "X_test = vect.transform(X_test)\n",
    "\n",
    "print('정확도: %.3f' % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 데이터 활용 문서 사용해서 모델 업데이트\n",
    "\n",
    "clf = clf.partial_fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습된 사이킷런 추정기 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "dest = os.path.join('movieclassifier', 'pkl_objects') \n",
    "\n",
    "if not os.path.exists(dest):\n",
    "    os.makedirs(dest)  # 'movieclassifier', 'pkl_objects' directory 생성\n",
    "    \n",
    "# 직렬화(serialization)\n",
    "pickle.dump(stop,  # 대상 객체\n",
    "            open(os.path.join(dest, 'stopwords.pkl'), 'wb'),  # 파이썬 객체가 저장될 파일 객체\n",
    "            protocol=4)  # 최신 pickle 프로토콜로 설정\n",
    "pickle.dump(clf,\n",
    "            open(os.path.join(dest, 'classifier.pkl'), 'wb'),\n",
    "            protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting vectorizer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile movieclassifier/vectorizer.py\n",
    "# 아래 스크립트 vectorizer.py 파일로 저장\n",
    "\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "cur_dir = os.path.dirname(__file__)\n",
    "stop = pickle.load(open(os.path.join(cur_dir,\n",
    "                                     'pkl_objects',\n",
    "                                     'stopwords.pkl'), 'rb'))\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower() +\n",
    "                  ' '.join(emoticons).replace('-', ''))\n",
    "    tokenized = [w for w in text.split() if w not in stop]\n",
    "    return tokenized\n",
    "\n",
    "vect = HashingVectorizer(decode_error='ignore',\n",
    "                         n_features=2**21,\n",
    "                         preprocessor=None,\n",
    "                         tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 디렉토리 'movieclassifier'로 변경\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir('movieclassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer 임포트하고 분류기 복원 코드 실행\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "from vectorizer import vect\n",
    "\n",
    "clf = pickle.load(open(os.path.join('pkl_objects',\n",
    "                                    'classifier.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측: 음성\n",
      "확률: 81.48%\n"
     ]
    }
   ],
   "source": [
    "# 복원한 분류기 객체로 문서 샘플 전처리 및 감성 레이블 예측\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "label = {0: '양성', 1: '음성'}\n",
    "example = ['I love this movie']\n",
    "\n",
    "X = vect.transform(example)\n",
    "\n",
    "print('예측: %s\\n확률: %.2f%%' %\\\n",
    "      (label[clf.predict(X)[0]],\n",
    "       np.max(clf.predict_proba(X))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터를 저장하기 위해 SQLite 데이터베이스 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLite 데이터베이스 생성 및 두 개의 영화 리뷰 저장\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('reviews.sqlite')  # SQLite 데이터베이스 파일 연결\n",
    "\n",
    "c = conn.cursor()  # 데이터베이스 커서 생성\n",
    "c.execute('DROP TABLE IF EXISTS review_db')\n",
    "c.execute('''CREATE TABLE review_db  \n",
    "          (review TEXT, sentiment INTEGER, date TEXT)''')  # review_db 테이블 생성. 컬럼 3개.\n",
    "\n",
    "example1 = 'I love this movie'\n",
    "c.execute('''INSERT INTO review_db\n",
    "           (review, sentiment, date) VALUES\n",
    "           (?, ?, DATETIME('now'))''', (example1, 1))\n",
    "\n",
    "example2 = 'I disliked this movie'\n",
    "c.execute('''INSERT INTO review_db\n",
    "           (review, sentiment, date) VALUES\n",
    "           (?, ?, DATETIME('now'))''', (example2, 0))\n",
    "\n",
    "conn.commit()  # 데이터베이스 변경사항 저장\n",
    "conn.close()  # 데이터베이스와 연결 닫음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I love this movie', 1, '2020-03-12 07:53:36'), ('I disliked this movie', 0, '2020-03-12 07:53:36')]\n"
     ]
    }
   ],
   "source": [
    "# 테이블 저장 확인\n",
    "\n",
    "conn = sqlite3.connect('reviews.sqlite')\n",
    "\n",
    "c = conn.cursor()\n",
    "c.execute('''SELECT * FROM review_db WHERE date\n",
    "           BETWEEN \"2017-01-01 00:00:00\" AND DATETIME('now')''')\n",
    "\n",
    "results = c.fetchall()\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(results)\n",
    "\n",
    "# SQLite 전용 데이터베이스 브라우저 사용 => 그래픽 인터페이스로 db확인 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 플라스크(Flask) 웹 애플리케이션 개발"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../1st_flask_app_1/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../1st_flask_app_1/app.py\n",
    "# app.py 파일 생성\n",
    "\n",
    "from flask import Flask, render_template\n",
    "\n",
    "app = Flask(__name__)  # 새로운 플라스크 인스턴스 __name__ 으로 초기화\n",
    "\n",
    "# templates 폴더 아래에 있는 HTML 파일 화면에 출력\n",
    "@app.route('/')  # 라우트 데코레이터: 특정 URL이 index함수를 실행하도록 지정\n",
    "def index():\n",
    "    return render_template('first_app.html')\n",
    "\n",
    "# 파이썬 인터프리터에 의해 직접 실행될 때만 run 메서드 사용\n",
    "if __name__ == '__main__':\n",
    "    app.run()  # 애플리케이션 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../1st_flask_app_2/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../1st_flask_app_2/app.py\n",
    "# 수정된 app.py 파일 생성\n",
    "\n",
    "from flask import Flask, render_template, request\n",
    "from wtforms import Form, TextAreaField, validators\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# 필요한 폼 필드 추가\n",
    "class HelloForm(Form):  # wtforms.Form 상속\n",
    "    sayhello = TextAreaField('', [validators.DataRequired()]) \n",
    "    \n",
    "# 시작 웹 페이지에 텍스트 필드 추가    \n",
    "@app.route('/')\n",
    "def index():\n",
    "    form = HelloForm(request.form)  # request.form: 사용자가 폼에 입력한 데이터   \n",
    "    return render_template('first_app.html', form=form)\n",
    "\n",
    "# HTML 폼으로 전달된 내용 검증한 후 hello.html 페이지를 출력\n",
    "@app.route('/hello', methods=['POST'])\n",
    "def hello():\n",
    "    form = HelloForm(request.form)\n",
    "    if request.method == 'POST' and form.validate():  # POST 방식 사용\n",
    "        name = request.form['sayhello']\n",
    "        return render_template('hello.html', name=name)\n",
    "    return render_template('first_app.html', form=form)\n",
    "\n",
    "# 웹 페이지에서 서버로 데이터를 보내는 방법\n",
    "# 1. GET 방식: URL 뒤에 파라미터를 붙임\n",
    "# 2. POST 방식: 전송 메시지 본문에 정보를 실음\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)  # 플라스크 디버거 활성화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영화 리뷰 분류기를 웹 애플리케이션으로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "# 메인 애플리케이션 app.py 구현\n",
    "\n",
    "from flask import Flask, render_template, request\n",
    "from wtforms import Form, TextAreaField, validators\n",
    "import pickle\n",
    "import sqlite3\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# 로컬 디렉터리에서 HashingVectorizer를 임포트합니다\n",
    "from vectorizer import vect\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "######## 분류기 준비\n",
    "cur_dir = os.path.dirname(__file__)\n",
    "clf = pickle.load(open(os.path.join(cur_dir, 'pkl_objects', 'classifier.pkl'), 'rb'))\n",
    "db = os.path.join(cur_dir, 'reviews.sqlite')\n",
    "\n",
    "def classify(document):\n",
    "    label = {0: 'negative', 1: 'positive'}\n",
    "    X = vect.transform([document])\n",
    "    y = clf.predict(X)[0]\n",
    "    proba = np.max(clf.predict_proba(X))\n",
    "    return label[y], proba\n",
    "\n",
    "def train(document, y):\n",
    "    X = vect.transform([document])\n",
    "    clf.partial_fit(X, [y])\n",
    "    \n",
    "def sqlite_entry(path, document, y):\n",
    "    conn = sqlite3.connect(path)\n",
    "    c = conn.cursor()\n",
    "    c.execute('''INSERT INTO review_db (review, sentiment, date)\n",
    "               VALUES (?, ?, DATETIME('now'))''', (document, y))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    \n",
    "######## 플라스크\n",
    "class ReviewForm(Form):\n",
    "    moviereview = TextAreaField('', [validators.DataRequired(),\n",
    "                                     validators.length(min=15)])  # 최소 15글자 이상 입력\n",
    "    \n",
    "@app.route('/')\n",
    "def index():\n",
    "    form = ReviewForm(request.form)\n",
    "    return render_template('reviewform.html', form=form)  # reviewform.html 파일로 출력\n",
    "\n",
    "@app.route('/results', methods=['POST'])\n",
    "def results():\n",
    "    form = ReviewForm(request.form)\n",
    "    if request.method == 'POST' and form.validate():\n",
    "        review = request.form['moviereview']\n",
    "        y, proba = classify(review)\n",
    "        return render_template('results.html',  # results.html 파일에 분류 결과 출력\n",
    "                               content=review,\n",
    "                               prediction=y,\n",
    "                               probability=round(proba*100, 2))\n",
    "    return render_template('reviewform.html', form=form)\n",
    "\n",
    "@app.route('/thanks', methods=['POST'])\n",
    "def feedback():\n",
    "    feedback = request.form['feedback_button']\n",
    "    review = request.form['review']\n",
    "    prediction = request.form['prediction']  # results.html 템풀랏에서 전달된 예측 클래스 레이블\n",
    "    inv_label = {'negative': 0, 'positive': 1}  # 정수 클래스 레이블로 변환\n",
    "    y = inv_label[prediction]\n",
    "    if feedback == 'Incorrect':\n",
    "        y = int(not(y))\n",
    "    train(review, y)  # 분류기 업데이트\n",
    "    sqlite_entry(db, review, y)  # SQLite 데이터베이스에 새로운 레코드로 피드백 추가\n",
    "    return render_template('thanks.html')  # thanks.html 템플릿 출력\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()  # 테스트 후 debug=True 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting update.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile update.py\n",
    "# 영화 분류기 업데이트\n",
    "# SQLite 데이터베이스에 수집된 피드백 데이터를 사용하여 예측 모델 업데이트\n",
    "\n",
    "import pickle\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 로컬 디렉터리에서 HashingVectorizer를 임포트합니다\n",
    "from vectorizer import vect\n",
    "\n",
    "def update_model(db_path, model, batch_size=10000):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    c.execute('SELECT * from review_db')\n",
    "    \n",
    "    results = c.fetchmany(batch_size)\n",
    "    while results:\n",
    "        data = np.array(result)\n",
    "        X = data[:, 0]\n",
    "        y = data[:, 1].astype(int)\n",
    "        \n",
    "        classes = np.array([0, 1])\n",
    "        X_train = vect.transform(X)\n",
    "        model.partial_fit(X_train, y, classes=classes)\n",
    "        results = c.fetchmany(batch_size)\n",
    "        \n",
    "    conn.close()\n",
    "    return model\n",
    "\n",
    "cur_dir = os.path.dirname(__file__)\n",
    "\n",
    "clf = pickle.load(open(os.path.join(cur_dir, 'pkl_objects', 'classifier.pkl'), 'rb'))\n",
    "db = os.path.join(cur_dir, 'reviews.sqlite')\n",
    "\n",
    "# clf = update_model(db_path=db, model=clf, batch_size=10000)\n",
    "\n",
    "# classifier.pkl 파일을 영구적으로 업데이트하려면\n",
    "# 다음 코드의 주석을 해제하세요\n",
    "\n",
    "# pickle.dump(clf, open(os.path.join(cur_dir, 'pkl_objects', 'classifier.pkl'),\n",
    "#             'wb', protocol=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "# 메인 애플리케이션 app.py 구현\n",
    "# update added version\n",
    "\n",
    "from flask import Flask, render_template, request\n",
    "from wtforms import Form, TextAreaField, validators\n",
    "import pickle\n",
    "import sqlite3\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# 로컬 디렉터리에서 HashingVectorizer를 임포트합니다\n",
    "from vectorizer import vect\n",
    "\n",
    "# 로컬 디렉터리에서 업데이트 함수를 임포트합니다\n",
    "from update import update_model\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "######## 분류기 준비\n",
    "cur_dir = os.path.dirname(__file__)\n",
    "clf = pickle.load(open(os.path.join(cur_dir, 'pkl_objects', 'classifier.pkl'), 'rb'))\n",
    "db = os.path.join(cur_dir, 'reviews.sqlite')\n",
    "\n",
    "def classify(document):\n",
    "    label = {0: 'negative', 1: 'positive'}\n",
    "    X = vect.transform([document])\n",
    "    y = clf.predict(X)[0]\n",
    "    proba = np.max(clf.predict_proba(X))\n",
    "    return label[y], proba\n",
    "\n",
    "def train(document, y):\n",
    "    X = vect.transform([document])\n",
    "    clf.partial_fit(X, [y])\n",
    "    \n",
    "def sqlite_entry(path, document, y):\n",
    "    conn = sqlite3.connect(path)\n",
    "    c = conn.cursor()\n",
    "    c.execute('''INSERT INTO review_db (review, sentiment, date)\n",
    "               VALUES (?, ?, DATETIME('now'))''', (document, y))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    \n",
    "######## 플라스크\n",
    "class ReviewForm(Form):\n",
    "    moviereview = TextAreaField('', [validators.DataRequired(),\n",
    "                                     validators.length(min=15)])  # 최소 15글자 이상 입력\n",
    "    \n",
    "@app.route('/')\n",
    "def index():\n",
    "    form = ReviewForm(request.form)\n",
    "    return render_template('reviewform.html', form=form)  # reviewform.html 파일로 출력\n",
    "\n",
    "@app.route('/results', methods=['POST'])\n",
    "def results():\n",
    "    form = ReviewForm(request.form)\n",
    "    if request.method == 'POST' and form.validate():\n",
    "        review = request.form['moviereview']\n",
    "        y, proba = classify(review)\n",
    "        return render_template('results.html',  # results.html 파일에 분류 결과 출력\n",
    "                               content=review,\n",
    "                               prediction=y,\n",
    "                               probability=round(proba*100, 2))\n",
    "    return render_template('reviewform.html', form=form)\n",
    "\n",
    "@app.route('/thanks', methods=['POST'])\n",
    "def feedback():\n",
    "    feedback = request.form['feedback_button']\n",
    "    review = request.form['review']\n",
    "    prediction = request.form['prediction']  # results.html 템풀랏에서 전달된 예측 클래스 레이블\n",
    "    inv_label = {'negative': 0, 'positive': 1}  # 정수 클래스 레이블로 변환\n",
    "    y = inv_label[prediction]\n",
    "    if feedback == 'Incorrect':\n",
    "        y = int(not(y))\n",
    "    train(review, y)  # 분류기 업데이트\n",
    "    sqlite_entry(db, review, y)  # SQLite 데이터베이스에 새로운 레코드로 피드백 추가\n",
    "    return render_template('thanks.html')  # thanks.html 템플릿 출력\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    clf = update_model(db_path=db,\n",
    "                       model=clf,\n",
    "                       batch_size=10000)\n",
    "    app.run()  # 테스트 후 debug=True 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
